# Copyright (C) 2019 NVIDIA Corporation.  All rights reserved.
# Licensed under the CC BY-NC-SA 4.0 license
# (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).

# logger options
image_save_iter: 8000       # How often do you want to save output images during training
snapshot_save_iter: 5000      # How often do you want to save trained models
log_iter: 1                   # How often do you want to log the training stats

# optimization options
max_iter: 350000             # maximum number of training iterations
weight_decay: 0.0001          # weight decay
lr_gen: 0.0001                # learning rate for the generator
lr_dis: 0.0001                # learning rate for the discriminator
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
gan_w: 1                      # weight of adversarial loss for image translation
fm_w: 1                       # weight on distance between gan features of style and translated image
r_w: 1                      # weight of image reconstruction loss

############################################
# loss options 
# no_D_xt_xa_recon       -> (Method1) x_a rescon, x_t rescon(parallel dataset use parallel_dataset)
# no_D_sc_recon:         -> (Method2) x_a rescon, c_x_ab&c_a recons, s_x_ab&s_b recons
# D                      -> (Method3) GAN
# no_D_AUTOVC            -> (Method4) paper(AUTOVC)
# only_self_recon        -> (Method5) only x_a rescon
      
loss_mode : no_D_AUTOVC 
#loss_mode : no_D_xt_xa_recon 
#loss_mode : no_D_sc_recon 

# model options
gen:
  mel_d : 512                 # dimension of input for content model(n_mel)
  kernel : 5                  # conv1d kernel size
  num_classes: 4              # dimension of the class for the class model(training set)
  latent_dim : 64            # style code
  ch : 64                     # channel in class model encoder
  content_dim : 6             # content code
dis:
  nf: 64                      # base number of filters
  n_res_blks: 8              # number of residual blocks in the discriminator
  num_classes: 4              # dimension of the class for the class model(training set)

# data options
num_workers: 0      ##################
batch_size: 5
fix_length : True       # random select 128 frames from 2s audio matrix
data_train: ./datasets/npy_txt/hung/2s_4class_512_no_normalize_no4/train
label_train: ./datasets/npy_txt/hung/2s_4class_512_no_normalize_no4/train
data_test: ./datasets/npy_txt/hung/2s_4class_512_no_normalize_no4/test
label_test: ./datasets/npy_txt/hung/2s_4class_512_no_normalize_no4/test

# pre-train/fine-tune options
#### 128
#style_pt: ./pre_ckpt/un_normalize_128/style/style_best_263.pt
#content_pt: ./pre_ckpt/un_normalize_128/content/content_019_en_best.pt
#pre_train: False

#### 512
style_pt: ./pre_ckpt/un_normalize_512_T=128/style/style_best_283.pt
content_pt: ./pre_ckpt/un_normalize_512_T=128/content/content_049_en_best.pt
pre_train: only_s      #all - pretrain style content都先定住 train一下decoder再fine-tune
                       #only_s - 只load style去train的版本 要觀察有沒content pretrain下的差異
not_use_style_loss: False #not use style loss    
fixed_s: False      # 如果是resume ->不load pretrain(pre_train=no)的情況下 定住style encoder去fine-tune
                    # 如果沒有resume ->load style的情況下 定住style encoder去fine-tune
exchange_train_mode: False
exchange_fre: 500   # exchage frequency

# inference options
outpath: recons_output         # test output path
source: test_audio/test/10_00.mp3   # source wave path
target: test_audio/test/09_02.mp3   # target wave path
model: outputs/funit_music_new_0520_Auto_blank_fine_tune_fixed_s/checkpoints  # model ckpt
content_size: 128
style_size: 87

